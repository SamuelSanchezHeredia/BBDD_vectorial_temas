"""
Base de datos vectorial con Pinecone + HuggingFace (sentence-transformers).
Lee el PDF Saberes_2ESO.pdf, genera embeddings y los almacena en Pinecone.
Permite hacer consultas por similitud semÃ¡ntica.

Estrategia de chunking semÃ¡ntico:
  1. Detecta secciones por encabezados (asignaturas, trimestres, tÃ­tulos).
  2. Dentro de cada secciÃ³n agrupa pÃ¡rrafos hasta alcanzar MAX_CHUNK_CHARS.
  3. Si un pÃ¡rrafo supera MAX_CHUNK_CHARS, lo divide por oraciones completas.
  4. Nunca corta palabras a mitad. Cada chunk hereda secciÃ³n y pÃ¡gina de origen.
"""

import os
import re
import sys
import time
import fitz  # PyMuPDF
from dotenv import load_dotenv
from pinecone import Pinecone, ServerlessSpec
from sentence_transformers import SentenceTransformer

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ConfiguraciÃ³n
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INDEX_NAME = "saberes-2eso"
EMBEDDING_MODEL = "paraphrase-multilingual-MiniLM-L12-v2"  # 384 dims, multilingÃ¼e (espaÃ±ol)
EMBEDDING_DIM = 384
MAX_CHUNK_CHARS = 800   # mÃ¡ximo de caracteres por chunk
MIN_CHUNK_CHARS = 60    # descartar chunks demasiado pequeÃ±os (ruido)
PDF_PATH = os.path.join(os.path.dirname(__file__), "Saberes_2ESO.pdf")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Funciones auxiliares
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_env():
    """Carga y valida las variables de entorno."""
    load_dotenv(os.path.join(os.path.dirname(__file__), ".env"))
    api_key = os.getenv("PINECONE_API_KEY")
    if not api_key or api_key.startswith("tu_clave"):
        print("âŒ ERROR: Falta la PINECONE_API_KEY en el archivo .env")
        sys.exit(1)
    return api_key


def extract_text_from_pdf(path: str) -> list[dict]:
    """Extrae texto del PDF pÃ¡gina a pÃ¡gina usando PyMuPDF."""
    doc = fitz.open(path)
    pages = []
    for i, page in enumerate(doc):
        text = page.get_text()
        if text.strip():
            pages.append({"text": text, "page": i + 1})
    doc.close()
    return pages


def is_heading(line: str) -> bool:
    """
    Detecta si una lÃ­nea es un encabezado de secciÃ³n (asignatura o tÃ­tulo principal).
    Solo marca como heading los nombres de asignaturas y tÃ­tulos del documento,
    NO los sub-apartados como '1.Âº trimestre' que son contenido dentro de la secciÃ³n.
    """
    line = line.strip()
    if not line or len(line) > 60:
        return False
    # Nombres de asignaturas conocidas
    patterns = [
        r"^(Lengua Castellana|MatemÃ¡ticas|Ciencias Naturales|Ciencias Sociales|"
        r"Historia|GeografÃ­a e Historia|BiologÃ­a|FÃ­sica y QuÃ­mica|"
        r"InglÃ©s|FrancÃ©s|Segunda Lengua|EducaciÃ³n FÃ­sica|TecnologÃ­a|"
        r"MÃºsica|PlÃ¡stica|Artes PlÃ¡sticas|ReligiÃ³n|Ã‰tica|FilosofÃ­a|"
        r"EconomÃ­a|InformÃ¡tica|LatÃ­n|Literatura|Valores CÃ­vicos|"
        r"EducaciÃ³n en Valores)",
        r"^Saberes bÃ¡sicos",                          # tÃ­tulo principal del documento
    ]
    for pattern in patterns:
        if re.match(pattern, line, re.IGNORECASE):
            return True
    return False


def split_by_sentences(text: str, max_chars: int) -> list[str]:
    """
    Divide un texto largo en fragmentos respetando oraciones completas.
    Corta por '. ', '.\n', '? ', '! ' sin partir palabras.
    """
    # Separar por fin de oraciÃ³n manteniendo el separador
    sentences = re.split(r'(?<=[.?!])\s+', text.strip())
    fragments = []
    current = ""
    for sentence in sentences:
        if len(current) + len(sentence) + 1 <= max_chars:
            current = (current + " " + sentence).strip()
        else:
            if current:
                fragments.append(current)
            # Si la oraciÃ³n sola supera el lÃ­mite, la aÃ±ade de todas formas
            # (no se puede dividir sin perder sentido)
            current = sentence
    if current:
        fragments.append(current)
    return fragments


def split_into_chunks(pages: list[dict]) -> list[dict]:
    """
    Chunking semÃ¡ntico en 3 niveles:
      1. Detecta encabezados â†’ marca inicio de nueva secciÃ³n.
      2. Agrupa pÃ¡rrafos de la misma secciÃ³n hasta MAX_CHUNK_CHARS.
      3. Si un pÃ¡rrafo solo ya supera MAX_CHUNK_CHARS, lo divide por oraciones.
    Cada chunk incluye: texto, pÃ¡gina, secciÃ³n (asignatura/trimestre).
    """
    chunks = []

    def flush_chunk(text: str, section: str, page: int):
        """AÃ±ade el chunk a la lista si supera el mÃ­nimo de caracteres."""
        text = text.strip()
        if len(text) >= MIN_CHUNK_CHARS:
            chunks.append({"text": text, "section": section, "page": page})

    current_section = "General"
    current_chunk = ""
    current_page = 1

    for page_data in pages:
        page_num = page_data["page"]
        lines = page_data["text"].split("\n")
        paragraph_buffer = ""

        for line in lines:
            stripped = line.strip()

            if not stripped:
                # LÃ­nea vacÃ­a â†’ fin de pÃ¡rrafo
                if paragraph_buffer.strip():
                    para = paragraph_buffer.strip()
                    paragraph_buffer = ""
                    if len(current_chunk) + len(para) + 2 <= MAX_CHUNK_CHARS:
                        current_chunk = (current_chunk + "\n\n" + para).strip()
                        current_page = page_num
                    else:
                        flush_chunk(current_chunk, current_section, current_page)
                        if len(para) > MAX_CHUNK_CHARS:
                            for frag in split_by_sentences(para, MAX_CHUNK_CHARS):
                                flush_chunk(frag, current_section, page_num)
                            current_chunk = ""
                        else:
                            current_chunk = para
                        current_page = page_num
                continue

            if is_heading(stripped):
                # Guardar lo acumulado antes de cambiar de secciÃ³n
                if paragraph_buffer.strip():
                    para = paragraph_buffer.strip()
                    paragraph_buffer = ""
                    current_chunk = (current_chunk + "\n\n" + para).strip() if current_chunk else para
                flush_chunk(current_chunk, current_section, current_page)
                current_chunk = ""
                current_section = stripped
                current_page = page_num
            else:
                paragraph_buffer = (paragraph_buffer + " " + stripped).strip()

        # Al acabar la pÃ¡gina, volcar el buffer restante
        if paragraph_buffer.strip():
            para = paragraph_buffer.strip()
            if len(current_chunk) + len(para) + 2 <= MAX_CHUNK_CHARS:
                current_chunk = (current_chunk + "\n\n" + para).strip()
            else:
                flush_chunk(current_chunk, current_section, current_page)
                if len(para) > MAX_CHUNK_CHARS:
                    for frag in split_by_sentences(para, MAX_CHUNK_CHARS):
                        flush_chunk(frag, current_section, page_num)
                    current_chunk = ""
                else:
                    current_chunk = para
            current_page = page_num

    # Volcar el Ãºltimo chunk pendiente
    flush_chunk(current_chunk, current_section, current_page)

    return chunks


def create_or_get_index(pc: Pinecone) -> None:
    """Crea el Ã­ndice en Pinecone si no existe y espera a que estÃ© listo."""
    existing = [idx.name for idx in pc.list_indexes()]
    if INDEX_NAME not in existing:
        print(f"   â†’ Creando Ã­ndice '{INDEX_NAME}' ({EMBEDDING_DIM} dimensiones)...")
        pc.create_index(
            name=INDEX_NAME,
            dimension=EMBEDDING_DIM,
            metric="cosine",
            spec=ServerlessSpec(cloud="aws", region="us-east-1"),
        )
        while not pc.describe_index(INDEX_NAME).status["ready"]:
            print("   â³ Esperando a que el Ã­ndice estÃ© listo...")
            time.sleep(2)
        print(f"   âœ… Ãndice creado.")
    else:
        print(f"   â„¹ï¸  El Ã­ndice '{INDEX_NAME}' ya existe.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ingesta
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ingest():
    """Lee el PDF, genera embeddings y los sube a Pinecone."""
    api_key = load_env()

    # 1. Leer PDF
    print(f"ğŸ“„ Leyendo PDF: {PDF_PATH}")
    pages = extract_text_from_pdf(PDF_PATH)
    print(f"   â†’ {len(pages)} pÃ¡ginas con texto.")

    # 2. Chunking semÃ¡ntico
    print(f"âœ‚ï¸  Aplicando chunking semÃ¡ntico (max={MAX_CHUNK_CHARS} chars por chunk)...")
    chunks = split_into_chunks(pages)
    print(f"   â†’ {len(chunks)} fragmentos generados.")

    # Mostrar resumen de secciones detectadas
    sections = sorted(set(c["section"] for c in chunks))
    print(f"   â†’ {len(sections)} secciones detectadas: {', '.join(sections)}")

    # 3. Generar embeddings con HuggingFace
    print(f"ğŸ¤— Cargando modelo de embeddings: {EMBEDDING_MODEL}")
    model = SentenceTransformer(EMBEDDING_MODEL)
    texts = [c["text"] for c in chunks]
    print(f"ğŸ”¢ Generando embeddings para {len(texts)} fragmentos...")
    embeddings = model.encode(texts, show_progress_bar=True, batch_size=64)

    # 4. Conectar con Pinecone y crear Ã­ndice
    print(f"ğŸŒ² Conectando con Pinecone...")
    pc = Pinecone(api_key=api_key)
    create_or_get_index(pc)
    index = pc.Index(INDEX_NAME)

    # 5. Borrar vectores anteriores para evitar duplicados en reingesta
    print(f"ğŸ—‘ï¸  Limpiando Ã­ndice anterior...")
    index.delete(delete_all=True)

    # 6. Subir vectores en lotes
    print(f"ğŸš€ Subiendo vectores a Pinecone...")
    batch_size = 100
    for i in range(0, len(chunks), batch_size):
        batch = []
        for j in range(i, min(i + batch_size, len(chunks))):
            vector_id = f"chunk-{j}"
            metadata = {
                "text":    chunks[j]["text"],
                "page":    chunks[j]["page"],
                "section": chunks[j]["section"],
            }
            batch.append((vector_id, embeddings[j].tolist(), metadata))
        index.upsert(vectors=batch)
        print(f"   â†’ Subidos {min(i + batch_size, len(chunks))}/{len(chunks)}")

    print(f"\nâœ… Ingesta completada: {len(chunks)} fragmentos en el Ã­ndice '{INDEX_NAME}'.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Consulta
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def query(question: str, top_k: int = 5):
    """Busca los fragmentos mÃ¡s relevantes para una pregunta."""
    api_key = load_env()

    model = SentenceTransformer(EMBEDDING_MODEL)
    q_embedding = model.encode(question).tolist()

    pc = Pinecone(api_key=api_key)
    index = pc.Index(INDEX_NAME)

    results = index.query(vector=q_embedding, top_k=top_k, include_metadata=True)

    print(f"\nğŸ” Pregunta: {question}")
    print(f"ğŸ“Š Top {top_k} resultados:\n")
    for i, match in enumerate(results["matches"], 1):
        score   = match["score"]
        text    = match["metadata"]["text"]
        page    = match["metadata"]["page"]
        section = match["metadata"].get("section", "â€”")
        print(f"  [{i}] (similitud: {score:.4f}) â€” {section} | PÃ¡gina {page}")
        print(f"      {text[:300]}...")
        print()

    return results


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Uso:")
        print("  python main.py ingest               â†’ Sube el PDF a Pinecone")
        print('  python main.py query "tu pregunta"  â†’ Busca en la base de datos')
        sys.exit(0)

    command = sys.argv[1]

    if command == "ingest":
        ingest()
    elif command == "query":
        if len(sys.argv) < 3:
            print("âŒ Debes proporcionar una pregunta. Ejemplo:")
            print('   python main.py query "Â¿QuÃ© saberes bÃ¡sicos hay en matemÃ¡ticas?"')
            sys.exit(1)
        question = " ".join(sys.argv[2:])
        query(question)
    else:
        print(f"âŒ Comando desconocido: {command}")
        print("   Usa 'ingest' o 'query'")

